services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 2181:2181
    networks:
      - kafka-net

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    restart: always
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - 9092:9092
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - kafka-net


  kafka-connect:
    build:
      context: .
      dockerfile: Dockerfile.connect
    container_name: kafka-connect
    depends_on:
      - kafka
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      ENABLE_DEBEZIUM_SCRIPTING: "true"
    ports:
      - 8083:8083
    volumes:
      - ./connectors:/kafka/connectors
      - connect_data:/kafka/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 10s
      timeout: 10s
      retries: 12
      start_period: 40s
    networks:
      - kafka-net


  connector-registrar:
    image: curlimages/curl:8.6.0
    container_name: connector-registrar
    depends_on:
      kafka-connect:
        condition: service_healthy
    volumes:
      - ./connectors:/connectors
    command: >
      sh -c '
      set -e;
      echo "Kafka Connect is healthy, registering connectors...";
      
      for f in /connectors/*.json; do
        [ -e "$$f" ] || continue;
        name=$(sed -n "s/^[[:space:]]*\"name\"[[:space:]]*:[[:space:]]*\"\(.*\)\".*/\1/p" "$$f" | head -n1);
        if [ -z "$$name" ]; then name=$(basename "$$f" .json); fi;
        echo "→ Applying $$name from $$f";
        code=$(curl -s -o /tmp/resp.json -w "%{http_code}" -X POST -H "Content-Type: application/json" --data @"$$f" http://kafka-connect:8083/connectors || true);
        if [ "$$code" = "201" ] || [ "$$code" = "200" ]; then
          echo "Applied $$name (created).";
        elif [ "$$code" = "409" ]; then
          echo "$$name exists — replacing via DELETE+POST.";
          curl -sS -o /tmp/resp.json -w "%{http_code}" -X DELETE http://kafka-connect:8083/connectors/$$name >/dev/null || true;
          code2=$(curl -s -o /tmp/resp.json -w "%{http_code}" -X POST -H "Content-Type: application/json" --data @"$$f" http://kafka-connect:8083/connectors || true);
          if [ "$$code2" = "201" ] || [ "$$code2" = "200" ]; then
            echo "Re-registered $$name";
          else
            echo "Failed to re-register $$name (HTTP $$code2):"; cat /tmp/resp.json; echo;
          fi;
        else
          echo "Failed to apply $$name (HTTP $$code):"; cat /tmp/resp.json; echo;
        fi;
      done;
      echo "All connectors processed.";
      '
    networks:
      - kafka-net



  mysql:
    image: mysql:8.0
    container_name: mysql
    restart: always
    env_file:
      - .env
    command: ["--default-authentication-plugin=mysql_native_password"]
    ports:
      - 3306:3306
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 20s
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql.cnf:/etc/mysql/conf.d/mysql.cnf:ro
    networks:
      - kafka-net

  adminer:
    image: adminer
    container_name: adminer
    restart: always
    ports:
      - 8080:8080
    depends_on:
      - mysql
    networks:
      - kafka-net

  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgrespass
      POSTGRES_DB: earthquake_sink
    ports:
      - "5435:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
    networks:
      - kafka-net

  earthquake_ingestor:
    build: .
    container_name: earthquake_ingestor
    restart: always
    env_file:
      - .env
    depends_on:
      mysql:
        condition: service_healthy
    working_dir: /app
    command: ["python", "-u", "ingestion/main.py"]
    networks:
      - kafka-net

  grafana:
    image: grafana/grafana:11.0.0
    container_name: grafana
    restart: always
    depends_on:
      - postgres
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
      - kafka-net

  kafka-ui:
      image: provectuslabs/kafka-ui:latest
      container_name: kafka-ui
      restart: always
      ports:
        - "8082:8080"  
      environment:
        KAFKA_CLUSTERS_0_NAME: local
        KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
        KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
        KAFKA_CLUSTERS_0_KAFKA_CONNECT_0_NAME: connect
        KAFKA_CLUSTERS_0_KAFKA_CONNECT_0_ADDRESS: http://kafka-connect:8083
      depends_on:
        - kafka
        - kafka-connect
      networks:
        - kafka-net

volumes:
  mysql_data:
  pg_data:
  kafka_data:
  connect_data:
  grafana_data:

networks:
  kafka-net:
    driver: bridge